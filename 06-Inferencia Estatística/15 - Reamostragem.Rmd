---
title       : Inferência Estatística
subtitle    : Reamostragem
author      : Delermando Branquinho Filho
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
---


## O canivete - (jackknife)

- O jackknife é uma ferramenta para estimar os erros-padrão e o viés dos estimadores
- Como o nome sugere, o jackknife é uma ferramenta pequena e útil; Em contraste com o bootstrap, que é então o equivalente moral de uma oficina gigante cheia de ferramentas
- Tanto o jackknife como o bootstrap envolvem dados de *reamostragem*; Ou seja, criar repetidamente novos conjuntos de dados a partir dos dados originais

---

## jackknife

- O jackknife apaga cada observação e calcula uma estimativa baseada no restante $n-1$ deles
- Usa esta coleção de estimativas para fazer coisas como estimar o viés e o erro padrão
- Observe que estimar o viés e ter um erro padrão não são necessários para coisas como meios de amostragem, que sabemos são estimativas imparciais de médias de população e quais são seus erros padrão

---


- Vamos considerar o jackknife para dados univariados
- Seja $X_1, \ldots, X_n$ uma coleção de dados usada para estimar um parâmetro $\theta$
- Seja $\hat \theta$ a estimativa com base no conjunto de dados completo
- Seja $\hat \theta_ {i}$ a estimativa de $\theta$ obtida pela *eliminação da observação $i$*
- Seja $\bar \theta = \frac {1} {n} \sum_ {i = 1} ^ n \hat \theta_ {i}$

---

## Continuando

- Então, a estimativa jackknife do viés é
   $$
   (n - 1) \left(\bar \theta - \hat \theta\right)
   $$
(Até que ponto a média de apagar-uma estimativa é a partir da estimativa real)
- A estimativa jackknife do erro padrão é
   $$
   \left[\frac{n-1}{n}\sum_{i=1}^n (\hat \theta_i - \bar\theta )^2\right]^{1/2}
   $$
(O desvio das estimativas de exclusão de uma estimativa de supressão média)

---

## Exemplo
### Queremos estimar o viés e o erro padrão da mediana

```{r, message=FALSE}
library(UsingR,quietly = TRUE,verbose = FALSE)
data(father.son)
x <- father.son$sheight
n <- length(x)
theta <- median(x)
jk <- sapply(1:n, function(i) median(x[-i])
             )
thetaBar <- mean(jk)
biasEst <- (n - 1) * (thetaBar - theta) 
seEst <- sqrt((n - 1) * mean((jk - thetaBar)^2))
c(biasEst, seEst)
```

---

## Exemplo

```{r}
library(bootstrap)
temp <- jackknife(x, median)
c(temp$jack.bias, temp$jack.se)
```

---

## Exemplo

- Ambos os métodos (naturalmente) rendem um `viés` (bias) estimado de `r temp$jack.bias` e um `se` de` r temp$jack.se`
- Pouco fato: a estimativa jackknife do viés para a mediana é sempre $0$ quando o número de observações é mesmo
- Foi mostrado que o jackknife é uma aproximação linear ao bootstrap
- Geralmente não use o jackknife para quantis da amostra como a mediana; Como como demonstrado, algumas propriedades são pobres

---

## Pseudo observações

- Outra maneira interessante de pensar sobre o jackknife usa pseudo observações
- Seja
$$
      \mbox{Pseudo Obs} = n \hat \theta - (n - 1) \hat \theta_{i}
$$
- Pense nestes como "qualquer observação $i$ contribui para a estimativa de $\theta$"
- Note quando $\hat \theta$ é a média da amostra, as pseudo-observações são os próprios dados
- Então o erro padrão da amostra destas observações é o erro padrão estimado jackknife anterior.
- A média dessas observações é uma estimativa corrigida de viés de $\theta$

---

## O bootstrap

- O bootstrap é uma ferramenta extremamente útil para construir intervalos de confiança e calcular erros padrão para estatísticas difíceis
- Por exemplo, como se derivaria um intervalo de confiança para a mediana?
- O procedimento bootstrap segue do chamado princípio bootstrap

---

## O princípio bootstrap

- Suponha que eu tenho uma estatística que estima alguns parâmetros de população, mas eu não sei a sua distribuição de amostragem
- O princípio bootstrap sugere a utilização da distribuição definida pelos dados para aproximar sua distribuição de amostragem

---

## O bootstrap na prática

- Na prática, o princípio bootstrap é sempre executado através da simulação
- Vamos abordar apenas alguns aspectos de reamostragem bootstrap
- O procedimento geral segue primeiro simulando conjuntos de dados completos a partir dos dados observados com substituição
- Trata-se aproximadamente de extrair amostras da distribuição dessa estatística, pelo menos na medida em que os dados são capazes de aproximar a verdadeira distribuição da população
- Calcular a estatística para cada conjunto de dados simulados
- Utilize as estatísticas simuladas para definir um intervalo de confiança ou tomar o desvio padrão para calcular um erro padrão

---
## Exemplo de algoritmo de bootstrap não paramétrico

- Procedimento de bootstrap para calcular o intervalo de confiança para a mediana a partir de um conjunto de dados de $ n $ observações

i. Exemplo de observações de $n$ **com substituição** dos dados observados resultando em um conjunto de dados completo simulado

ii. Pegue a mediana do conjunto de dados simulados

iii. Repita estes dois passos $B$ vezes, resultando em $B$ simulados medianas

iv. Essas medianas são aproximadamente tiradas da distribuição de amostragem da mediana de $ n $ observações; Portanto, podemos

- Desenhe um histograma deles
- Calcular seu desvio padrão para estimar o erro padrão da mediana
- Pegue os percentis $2.5 ^ {th}$ e $97.5 ^ {th}$ como um intervalo de confiança para a mediana

---

## Exemplo de código

```{r}
B <- 1000
resamples <- matrix(sample(x,n * B,replace = TRUE),B, n)
medians <- apply(resamples, 1, median)
sd(medians)
quantile(medians, c(.025, .975))
```

---
## Histograma de resamples bootstrap

```{r, fig.height=5, fig.width=5}
hist(medians)
```

---

## Notas sobre o bootstrap

- O bootstrap não é paramétrico
- Melhora o percentil dos intervalos de confiança para viés correto 
- Existem muitas variações nos procedimentos bootstrap; O livro "Uma Introdução ao Bootstrap" "por Efron e Tibshirani é um ótimo lugar para começar tanto para bootstrap e informação jackknife


---

## Comparações de grupos
- Considere comparar dois grupos independentes.
- Exemplo, comparando as pulverizações B e C

```{r, fig.height=4, fig.width=4}
data(InsectSprays)
boxplot(count ~ spray, data = InsectSprays)
```

---

## Testes de Permutação
- Considere a hipótese nula de que a distribuição das observações de cada grupo é a mesma
- Então, os rótulos de grupo são irrelevantes
- Então descartamos os níveis do grupo e permute os dados combinados
- Divida os dados permutados em dois grupos com $n_A$ e $n_B$ observações (digamos sempre tratando as primeiras observações de $n_A$ como o primeiro grupo)
- Avaliar a probabilidade de obter uma estatística tão grande ou maior do que a observada
- Um exemplo estatístico seria a diferença nas médias entre os dois grupos; pode-se também usar um teste estatístico t

---

## Variações no teste de permutação

Tipo de dados | Estatística | Nome do teste
--- | --- | --- |
Rank | Pontuação | Teste de pontuação
Binário | Problema hipergeométrico | Teste exato de Fisher
Dados brutos | | Teste de permutação normal

- Além disso, os chamados *testes de aleatorização* são exatamente testes de permutação, com uma motivação diferente.
- Para dados combinados, pode-se aleatorizar os sinais
- Para as fileiras, isso resulta no teste de classificação assinado
- Estratégias de permutação funcionam também para regressão
- Permissão de um regressor de interesse
- Os testes de permutação funcionam muito bem em contextos multivariados

---

## Teste de permutação para dados de pesticidas

```{r}
subdata <- InsectSprays[InsectSprays$spray %in% c("B", "C"),]
y <- subdata$count
group <- as.character(subdata$spray)
testStat <- function(w, g) mean(w[g == "B"]) - mean(w[g == "C"])
observedStat <- testStat(y, group)
permutations <- sapply(1 : 10000, function(i) testStat(y, sample(group)))
observedStat
mean(permutations > observedStat)
```

---

## Histograma de permutações
```{r, fig.width=5, fig.height=5}
hist(permutations)
```


## bootstrap

O exemplo a seguir gera o intervalo de confiança de 95% de bootstrap para R-quadrado na regressão linear de milhas por galão (mpg) no peso do carro (peso) e deslocamento (disp). A fonte de dados é mtcars. O intervalo de confiança bootstrap baseia-se em 1000 repetições.

```{r message=FALSE}
# Bootstrap 95% CI for R-Squared
library(boot,quietly = TRUE,verbose = FALSE)
# function to obtain R-Squared from the data 
rsq <- function(formula, data, indices) {
  d <- data[indices,] # allows boot to select sample 
  fit <- lm(formula, data=d)
  return(summary(fit)$r.square)
} 
# bootstrapping with 1000 replications 
results <- boot(data=mtcars, statistic=rsq, 
  	R=1000, formula=mpg~wt+disp)

# view results
results 
plot(results)

# get 95% confidence interval 
boot.ci(results, type="bca")
```

**BCA - bias-corrected and accelerated**

Outros valores possíveis: `c("norm","basic", "stud", "perc", "bca", "all")`

### Para todos os tipos:
```{r}
boot.ci(results, type="all")

```




.