---
title       : Inferência Estatística
subtitle    : Agrupamentos
author      : Delermando Branquinho Filho
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
---

## Grupo independente $t$ intervalos de confiança

- Suponha que queremos comparar a pressão arterial média entre dois grupos em um estudo randomizado; Aqueles que receberam o tratamento para aqueles que receberam um placebo
- Não podemos usar o teste t emparelhado porque os grupos são independentes e podem ter tamanhos de amostra diferentes
- Apresentamos agora métodos para comparar grupos independentes

---

## Notação

- Deixe $X_1,\ldots,X_{n_x}$ ser iid $N(\mu_x,\sigma^2)$
- Deixe $Y_1,\ldots,Y_{n_y}$ ser iid $N(\mu_y, \sigma^2)$
- Deixe $\bar X$, $\bar Y$, $S_x$, $S_y$ Ser a média e desvios-padrão
- Usando o fato de que combinações lineares de normais são novamente normais, sabemos que $\bar Y - \bar X$ Também é normal com média $\mu_y - \mu_x$ e variância $\sigma^2 (\frac{1}{n_x} + \frac{1}{n_y})$
- O estimador de variância combinado $$S_p^2 = \{(n_x - 1) S_x^2 + (n_y - 1) S_y^2\}/(n_x + n_y - 2)$$ É um bom estimador de $\sigma^2$

---

## Nota

- O estimador combinado é uma distribuição das variâncias do grupo, colocando maior peso em qualquer que tenha um maior tamanho da amostra
- Se os tamanhos de amostra forem os mesmos, a estimativa de variância agrupada é a média das variâncias do grupo
- O estimador combinado é imparcial

$$
    \begin{eqnarray*}
    E[S_p^2] & = & \frac{(n_x - 1) E[S_x^2] + (n_y - 1) E[S_y^2]}{n_x + n_y - 2}\\
            & = & \frac{(n_x - 1)\sigma^2 + (n_y - 1)\sigma^2}{n_x + n_y - 2}
    \end{eqnarray*}
$$
- A estimativa de variância agrupada é independente de $\bar Y - \bar X$ dado que $S_x$ é independente de $\bar X$ e $S_y$ é independente de $\bar Y$ e os grupos são independentes

---

## Resultado

- A soma de duas variáveis aleatórias independentes `Chi-quadrado` é Chi-quadrado com graus de liberdade iguais à soma dos graus de liberdade dos summands
- Assim sendo

$$
    \begin{eqnarray*}
      (n_x + n_y - 2) S_p^2 / \sigma^2 & = & (n_x - 1)S_x^2 /\sigma^2 + (n_y - 1)S_y^2/\sigma^2 \\ \\
      & = & \chi^2_{n_x - 1} + \chi^2_{n_y-1} \\ \\
      & = & \chi^2_{n_x + n_y - 2}
    \end{eqnarray*}
$$

**Lembrando**
`Para que serve?`

**Quiq-uadrado**, simbolizado por χ2 é um teste de hipóteses que se destina a encontrar um valor da **dispersão** para duas variáveis nominais, avaliando a associação existente entre variáveis qualitativas. É um teste não paramétrico, ou seja, não depende dos parâmetros populacionais, como média e variância.

`Variáveis Qualitativas` (ou categóricas): são as características que não possuem valores quantitativos, mas, ao contrário, são definidas por várias categorias, ou seja, representam uma classificação dos indivíduos. Podem ser nominais ou ordinais.  
`Variáveis nominais`: não existe ordenação dentre as categorias.

---

### Juntando tudo isso

- A estatística
$$
    \frac{\frac{\bar Y - \bar X - (\mu_y - \mu_x)}{\sigma \left(\frac{1}{n_x} + \frac{1}{n_y}\right)^{1/2}}}%
    {\sqrt{\frac{(n_x + n_y - 2) S_p^2}{(n_x + n_y - 2)\sigma^2}}}
    = \frac{\bar Y - \bar X - (\mu_y - \mu_x)}{S_p \left(\frac{1}{n_x} + \frac{1}{n_y}\right)^{1/2}}
$$
É um padrão normal dividido pela raiz quadrada de um Chi-quadrado independente dividido por seus graus de liberdade
- Portanto esta estatística segue a distribuição $t$ de Gosset com $n_x + n_y - 2$ graus de liberdade
- Observe que o formulário é (estimador - valor verdadeiro) / SE

**Chi-quadrado** - A distribuição χ2 ou Chi-quadrado é uma das distribuições mais utilizadas em estatística inferencial, principalmente para realizar testes de `χ2`. Este teste serve para avaliar quantitativamente a relação entre o resultado de um experimento e a distribuição esperada para o fenômeno. Isto é, ele nos diz com quanta certeza os valores observados podem ser aceitos como regidos pela teoria em questão. Muitos outros testes de hipótese usam, também, a distribuição `χ2`.

---

## Intervalo de Confiança

- Portanto, um $(1 - \alpha)\times 100\%$ Intervalo de confiança para $\mu_y - \mu_x$ é

$$
    \bar Y - \bar X \pm t_{n_x + n_y - 2, 1 - \alpha/2}S_p\left(\frac{1}{n_x} + \frac{1}{n_y}\right)^{1/2}
$$
- Lembre-se que este intervalo está assumindo uma variância constante entre os dois grupos
- Se houver alguma dúvida, assumir uma variação diferente por grupo, que discutiremos mais tarde

---


## Exemplo
### Baseado em Rosner, Fundamentals of Biostatistics

- Comparando PAS para 8 usuários de contraceptivos orais versus 21 controles
- $\bar X_{OC} = 132.86$ mmHg com $s_{OC} = 15.34$ mmHg
- $\bar X_{C} = 127.44$ mmHg com $s_{C} = 18.23$ mmHg
- Estimativa de variância agrupada

```{r}
sp <- sqrt((7 * 15.34^2 + 20 * 18.23^2) / (8 + 21 - 2))
132.86 - 127.44 + c(-1, 1) * qt(.975, 27) * sp * (1 / 8 + 1 / 21)^.5
```

---

```{r}
data(sleep)
x1 <- sleep$extra[sleep$group == 1]
x2 <- sleep$extra[sleep$group == 2]
n1 <- length(x1)
n2 <- length(x2)
sp <- sqrt( ((n1 - 1) * sd(x1)^2 + (n2-1) * sd(x2)^2) / (n1 + n2-2))
md <- mean(x1) - mean(x2)
semd <- sp * sqrt(1 / n1 + 1/n2)
md + c(-1, 1) * qt(.975, n1 + n2 - 2) * semd
t.test(x1, x2, paired = FALSE, var.equal = TRUE)$conf
t.test(x1, x2, paired = TRUE)$conf
```

---


## Ignorando o emparelhamento
```{r, fig.width=5, fig.height=5}
plot(c(0.5, 2.5), range(x1, x2), type = "n", frame = FALSE, xlab = "group", ylab = "Extra", axes = FALSE)
axis(2)
axis(1, at = 1:2, labels = c("Group 1", "Group 2"))
for (i in 1:n1) lines(c(1, 2), c(x1[i], x2[i]), lwd = 2, col = "red")
for (i in 1:n1) points(c(1, 2), c(x1[i], x2[i]), lwd = 2, col = "black", bg = "salmon", pch = 21, cex = 3)
```


## Com emparelhamento
```{r, fig.width=5, fig.height=5}
x1 <- sort(x1)
x2 <- sort(x2)
plot(c(0.5, 2.5), range(x1, x2), type = "n", frame = FALSE, xlab = "group", ylab = "Extra", axes = FALSE)
axis(2)
axis(1, at = 1:2, labels = c("Group 1", "Group 2"))
for (i in 1:n1) lines(c(1, 2), c(x1[i], x2[i]), lwd = 2, col = "red")
for (i in 1:n1) points(c(1, 2), c(x1[i], x2[i]), lwd = 2, col = "black", bg = "salmon", pch = 21, cex = 3)
```



---

## Variações desiguais

- Sob variâncias desiguais
$$
    \bar Y - \bar X \sim N\left(\mu_y - \mu_x, \frac{s_x^2}{n_x} + \frac{\sigma_y^2}{n_y}\right)
$$
- A estatística
$$
    \frac{\bar Y - \bar X - (\mu_y - \mu_x)}{\left(\frac{s_x^2}{n_x} + \frac{\sigma_y^2}{n_y}\right)^{1/2}}
$$
Aproximadamente segue a distribuição $t$ de Gosset com graus de liberdade iguais a

$$
    \frac{\left(S_x^2 / n_x + S_y^2/n_y\right)^2}
    {\left(\frac{S_x^2}{n_x}\right)^2 / (n_x - 1) +
      \left(\frac{S_y^2}{n_y}\right)^2 / (n_y - 1)}
$$

---

## Exemplo

- Comparando PAS para 8 usuários contraceptivos orais versus 21 controles
- $\bar X_{OC} = 132.86$ mmHg com $s_{OC} = 15.34$ mmHg
- $\bar X_{C} = 127.44$ mmHg com $s_{C} = 18.23$ mmHg
- $df=15.04$, $t_{15.04, .975} = 2.13$
- Intervalo

$$
132.86 - 127.44 \pm 2.13 \left(\frac{15.34^2}{8} + \frac{18.23^2}{21} \right)^{1/2}
= [-8.91, 19.75]
$$
- Em R, `t.test(..., var.equal = FALSE)`

---

## Comparando outros tipos de dados

* Para dados binomiais, há muitas maneiras de comparar dois grupos de risco relativo, diferença de risco, odds ratio.
* Teste Chi-quadrado, aproximações normais, testes exatos.
* Para dados de contagem, há também testes de Chi-quadrado e testes exatos.
* Vamos deixar as discussões para comparar grupos de dados para binário e contagem de dados até cobertura glms na classe de regressão.

---

**Observação Importante**

Em estatística, os testes de normalidade são usados para determinar se um conjunto de dados de uma dada variável aleatória, é bem modelada por uma distribuição normal ou não, ou para calcular a probabilidade da variável aleatória subjacente estar normalmente distribuída.

## Exemplo

**PARA AMOSTRAS INDEPENDENTES**

Sobre a perda de peso (kg) em dois grupos de pacientes; cada paciente seguindo a dieta designada para seu grupo.

```{r}
Dieta1<-c(12,8,15,13,10,12,14,11,12,13)
Dieta2<-c(15,19,15,12,13,16,15)
```

Verifique normalidade dos dados

```{r message=FALSE,warning=FALSE}
shapiro.test(Dieta1)
shapiro.test(Dieta2)
```

Verifique homogeneidade das variâncias usando o teste de F

```{r}
var.test(Dieta1,Dieta2)

```


Os dados são normais e as variâncias não são significativamente diferentes. Podemos prosseguir com o teste-t para as duas amostras independentes, mas com variâncias iguais. A hipótese nula é que não há uma diferença na perda de massa média e a alternativa é que há uma diferença. O teste é de duas caudas.

```{r}
t.test(Dieta1,Dieta2, var.equal=TRUE,alternative="two.sided")
```

Como pode ser visto no resultado, há uma diferença significativa em perda de massa média e a perda de peso é maior para os pacientes seguindo a dieta 2.

**PARA AMOSTRAS PAREADAS**

A massa de 10 pássaros migratórios foi medida em duas ocasiões, primeiro em agosto e os mesmos pássaros (marcados individualmente e recapturados) foram remedidos em setembro.



```{r}
ago<-c(10.3,11.4,10.9,12.0,10.0,11.9,12.2,12.3,11.7,12.0)
set<-c(12.2,12.1,13.1,11.9,12.0,12.9,11.4,12.1,13.5,12.3)
boxplot(ago,set,names=c("Agosto","Setembro"))

```

```{r}
shapiro.test(ago)
shapiro.test(set)
var.test(ago,set)

```

Os dados são normais e as variâncias são homogêneas. Rode o teste-t com as duas amostras pareadas. O teste é de duas caudas e com as variâncias iguais.

```{r}
t.test(ago,set,paired=TRUE,alternative="two.sided", var.equal=TRUE)

```


O resultado indica que há uma diferença significativa entre as médias das duas amostras e concluímos que o aumento em massa média entre agosto e setembro é significate.
