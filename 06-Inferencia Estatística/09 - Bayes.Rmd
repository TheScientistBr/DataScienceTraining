---
title       : Inferência Estatística
subtitle    : Bayes
author      : Delermando Branquinho Filho
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
---



## Introdução

A análise bayesiana deixou de ser algo fantástico para um procedimento comum. Precisamos ter cuidado com alguns usos e terminologias. Uma regressão logística bayesiana ainda é apenas regressão logística. A parte bayesiana entra em jogo com a perspectiva sobre a probabilidade de que alguém use para interpretar os resultados e em como as estimativas são alcançadas.

A abordagem bayesiana da análise de dados requer uma maneira diferente de pensar sobre as coisas, mas sua implementação pode ser vista como uma extensão das abordagens tradicionais. De fato, como veremos mais adiante, incorpora a própria probabilidade de usar em técnicas estatísticas tradicionais. A diferença fundamental considera a noção de probabilidade, que, embora diferente das estatísticas de pescadores ou de frequentadores, é realmente mais parecida com a forma como as pessoas pensam sobre a probabilidade. Além disso, os valores-p e os intervalos terão a interpretação de que muitos pesquisadores aplicados pensam incorretamente que seus métodos atuais fornecem. Além disso, obtém uma caixa de ferramentas muito flexível que pode lidar com muitas análises complexas. Em suma, o motivo de se envolver na análise bayesiana é que ele tem muito a oferecer e pode potencialmente lidar com o que você joga nela.

## Probabilidade Bayesiana

Esta seção terá sobre todas as matemáticas que haverá nesta brochura e será muito mínima mesmo assim. O foco será no entendimento conceitual, e posteriormente ilustrado com um exemplo.

## Probabilidade condicional e teorema de Bayes

O teorema de Bayes é ilustrado em termos de probabilidade da seguinte forma:

$$P (A | B) = \frac{p (B | A) p (A)}{p(B)}$$

Em suma, estamos tentando verificar a probabilidade condicional de $A$ dado $B$ com base na probabilidade condicional de $B$ dado $A$ e as respectivas probabilidades de $A$ e $B$. Isso talvez não seja inteiramente esclarecedor em si mesmo, então vamos enquadrá-lo de outras maneiras, e para as próximas representações, ignoraremos o denominador.


Aqui está mais uma maneira de considerar isso:

$$Crença\_atualizada = \frac{evidência\_atual * crença\_prévia} {evidência}$$


### Um exemplo prático

**Prioridade, probabilidade e distribuições a posteriore**

O seguinte é uma tentativa de fornecer um pequeno exemplo para mostrar a conexão entre distribuição prévia (a-priori), probabilidade e distribuição posteriori. Digamos que queremos estimar a probabilidade de que alguém na estrada digite durante a condução. Vamos empregar a distribuição binomial para modelar.

Nosso objetivo é estimar um parâmetro $\theta$, a probabilidade de que o motorista de um carro esteja enviando mensagens de texto. Você tira uma amostra aleatória de dez carros enquanto dirige para casa e observa o seguinte:

- passar três carros, as cabeças dos motoristas estavam encarando suas voltas.
- Você observa dois carros que parecem estar sendo dirigindos normalmente.
- Outros dois carros estavam se desviando para outras pistas.
- Dois carros mais parecem estar dirigindo normalmente.
- Com um semáforo, um carro desperdiça 10 segundos do tempo de todos os outros antes de perceber que o semáforo ficou verde. 

Podemos representar isso em R da seguinte forma, bem como configurar algumas outras coisas para mais tarde.

```{r}
drive = c('texting','texting','texting','not','not',
          'texting','texting','not','not','texting')

# convert to numeric, arbitrarily picking texting=1, not=0
driveNum = ifelse(drive=='texting', 1, 0)
N = length(drive)                      # sample size
nTexting = sum(drive=='texting')       # number of drivers texting
nNot = sum(drive=='not')               # number of those not
```


Lembre-se da distribuição binomial onde especificamos o número de testes para uma observação particular e a probabilidade de um evento. Vejamos a distribuição de alguns valores para $\theta$ igual a $0.5$ e $0.85$ e $N = 10$ observações. Vamos repetir isso $1000$ vezes (histogramas não mostrados).

```{r}
x1 = rbinom(1000, size=10, p=.5)
x2 = rbinom(1000, size=10, p=.85)

mean(x1); hist(x1)
mean(x2); hist(x2)
```

Podemos ver que as medias estão em torno de $N*p$ como esperamos com o binômio.

## A Priori

Para a nossa situação atual, não conhecemos $\theta$ e estamos tentando estimá-lo. Começaremos fornecendo alguns valores possíveis.


```{r}
theta = seq(from=1/(N+1), to=N/(N+1), length=10)
```

Para a abordagem bayesiana, devemos escolher uma distribuição prévia que represente nossas crenças iniciais sobre a estimativa. Eu forneço três possibilidades e notei que qualquer um deles funcionaria bem para esta situação. Nós iremos com uma distribuição triangular, que colocará a maior parte do peso em direção a valores em torno de $0.5$ enquanto falaremos mais sobre isso mais tarde, vou seguir em frente e mencionar que é aqui que alguns expressaram especificamente problemas com a estimativa bayesiana no passado, porque essa parte do processo é muito subjetiva.

Deixando de lado o fato de que a subjetividade é uma parte inerente do processo científico e que ignorar a informação prévia (se explicitamente disponível da pesquisa anterior) seria descaradamente não científico, o principal ponto a seguir é que essa escolha não é arbitrária. Existem muitas distribuições com as quais podemos trabalhar, mas algumas serão melhores para nós do que outras. Mais uma vez, vamos revisar este tópico mais tarde.

```{r}
### prior distribution
# uniform
pTheta = dunif(theta)

# triangular as in Kruschke
pTheta = pmin(theta, 1-theta)

# beta prior with mean = .5


pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
```


Assim, dada uma estimativa de $θ$, temos uma probabilidade desse valor com base no nosso pré-requisito.

### Probabilidade

Em seguida, calcularemos a probabilidade de os dados terem dado algum valor de $θ$. A função de verossimilhança para o binômio pode ser expressa como:

$$p(y|θ)=(\frac{N}{k})θ^k(1−θ)^{N−k}$$

Onde $N$ é **o número total de tempos possíveis em que o evento de interesse poderia ocorrer** e $k$ **número de vezes que o evento de interesse ocorre**. Nossa estimativa de máxima verossimilhança nesta configuração simples seria simplesmente a proporção de eventos testemunhados a partir do número total de amostras. 

Usaremos a fórmula apresentada acima. Observe que, se tivéssemos covariáveis como em um modelo de regressão, teríamos estimativas diferentes de theta para cada observação e, portanto, calcularíamos a probabilidade de cada observação e, em seguida, levaria seu produto ou somaríamos seus valores. Mesmo aqui, se você transformar isso em regressão logística binária com 10 resultados de mensagens de texto versus não, o modelo seria idêntico aos nossos resultados aqui. Tecnicamente, o primeiro termo não é necessário, mas serve para normalizar a probabilidade como fizemos com o anterior.


```{r}
pDataGivenTheta = choose(N, nTexting) * theta^nTexting * (1-theta)^nNot
```


### A Posteriori

Dado o anterior e a probabilidade, agora podemos calcular a distribuição a posteriori através do teorema de Bayes.

```{r}
# Primeiro calculamos o denominador do teorema de Bayes; Este é o marginal
# Probabilidade de y
pData = sum(pDataGivenTheta*pTheta)

pThetaGivenData = pDataGivenTheta*pTheta  / pData  # Bayes theorem
```

Agora vamos examinar o que temos.


```{r}
data.frame(theta, prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)
```


Podemos ver que temos dado a maioria da nossa probabilidade anterior aos valores do meio, com a probabilidade diminuindo lentamente em direção a qualquer extremo. A probabilidade sugere que os dados sejam mais prováveis para os valores de $θ .55-.64$, embora nós conheçemos a estimativa de máxima verossimilhança específica para $θ$ é a proporção para a amostra, ou $0.6$. Nosso a posteriori irá cair em algum lugar entre as estimativas a priori e de verossimilhança, e podemos ver que mudou a maior parte da probabilidade ligeiramente para longe do centro do valor anterior a $θ$ de 0.6.

Vamos em frente e vamos ver  qual é o significado:

```{r}
posteriorMean = sum(pThetaGivenData*theta)
posteriorMean
```

Então começamos com um valor a priori  centrado em um valor de $θ = 0.5$, adicione dados cuja estimativa ML é $θ = 0.6$, e nossa distribuição posterior sugere que terminamos em algum lugar intermediário.

Talvez possamos entender isso mais através dos gráficos abaixo. Em cada um destes, a priori é representado pela densidade azul, a probabilidade pelo vermelho e a porteriori pelo roxo. O primeiro é baseado em um a priori diferente do que apenas usado em nosso exemplo e, em vez disso, emprega  a distribuição beta observada entre as possibilidades no código acima. 

Embora a distribuição beta seja altamente flexível, com os parâmetros de forma $A$ e $B$ definidos para 10 e 10, obtemos uma distribuição simétrica centrada em $θ = 0.5$. Este seria realmente um pouco mais forte antes do que normalmente podemos querer usar, mas serve para ilustrar um ponto. A média do beta é $A + B$ e, portanto, tem uma boa interpretação como prioridade com dados com tamanho de amostra igual a $A + B$. A distribuição a posteriori que resulta em uma metade em algum lugar entre o valor de máxima verossimilhança e o valor priori Com o a priori mais forte, o a posteriori é puxado para mais perto disso.

O segundo gráfico utiliza uma prioridade mais difusa de β (2,2) β (1,1)  é uma distribuição uniforme. O resultado do uso do valor a priori é que a probabilidade acumula mais peso em relação à a posteriori. Na verdade, se usássemos uma distribuição uniforme, estaríamos fazendo o equivalente à estimativa de máxima verossimilhança. Como tal, a maioria dos métodos comumente usados que implementam a máxima verossimilhança podem ser vistos como um caso especial de uma abordagem Bayesiana.

O terceiro gráfico emprega novamente o primeiro β (10,10) inicial, mas desta vez adicionamos mais observações aos dados. Mais uma vez isso serve para dar mais peso à probabilidade, o que é o que queremos. Como cientistas, queremos a evidência, ou seja, dados, para superar eventualmente nossas crenças anteriores sobre o estado das coisas quanto mais temos.

